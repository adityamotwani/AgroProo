{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lat_color",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJ40Fdncsuwgk1eGh54Aix",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityamotwani/AgroProo/blob/main/lat_color.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OhnBj8HueMS",
        "outputId": "aa0ed902-293e-402b-cd8a-c0857dde44c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"TexSoup==0.3.1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09f-DQgnmC6b",
        "outputId": "f1778017-bc67-40e4-c5fc-c06daf2056f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: TexSoup==0.3.1 in /usr/local/lib/python3.7/dist-packages (0.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from TexSoup import TexSoup\n",
        "with open('latex/conference_101719.tex', mode='r',encoding=\"utf8\") as f:\n",
        "  toc = TexSoup(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q99OSI8vhr8_",
        "outputId": "7ebbf3e3-1a6a-46e0-94a9-e49fbe2eee13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\newcommand{\\q}[1]{``#1''}\n",
            "\n",
            "\\documentclass[conference]{IEEEtran}\n",
            "\\IEEEoverridecommandlockouts\n",
            "% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.\n",
            "\\usepackage{cite}\n",
            "\\usepackage{amsmath,amssymb,amsfonts}\n",
            "\\usepackage{algorithmic}\n",
            "\\usepackage{graphicx}\n",
            "\\usepackage{textcomp}\n",
            "\\usepackage{xcolor}\n",
            "\\usepackage[export]{adjustbox}\n",
            "\\def{\\}{BibTeX}{{\\rm B\\kern-.05em{\\sc i\\kern-.025em b}\\kern-.08em\n",
            "    T\\kern-.1667em\\lower.7ex\\hbox{E}\\kern-.125emX}}\n",
            "\\begin{document}\n",
            "\n",
            "\\title{Soil Analysis and Crop Recommendation using Machine Learning}\n",
            "\n",
            "\\makeatletter\n",
            "\\newcommand{\\linebreakand}{%\n",
            "  \\begin{@IEEEauthorhalign}\n",
            "  \\hfill\\mbox{}\\par\n",
            "  \\mbox{}\\hfill\\end{@IEEEauthorhalign}\n",
            "}\n",
            "\\makeatother\n",
            "\\makeatletter\n",
            "\\newcommand\\thefontsize{\\expandafter\\string\\the\\font}\n",
            "\\makeatother\n",
            "\n",
            "\\author{\\IEEEauthorblockN{\\colorbox{violet}{\\color{violet}Aditya} \\colorbox{violet}{\\color{violet}Motwani}\\IEEEauthorrefmark{1},Param Patil\\IEEEauthorrefmark{2},Vatsa Nagaria\\IEEEauthorrefmark{3},Shobhit Verma\\IEEEauthorrefmark{4},Sunil Ghane\\IEEEauthorrefmark{5}}\n",
            "\\IEEEauthorblockA{Department of  Computer Engineering,\n",
            "Sardar Patel Institute Of Technology, Mumbai, India\\\\\n",
            "\\IEEEauthorrefmark{1}aditya.motwani@spit.ac.in,\n",
            "\\IEEEauthorrefmark{2}param.patil@spit.ac.in,\n",
            "\\IEEEauthorrefmark{3}vatsa.nagaria@spit.ac.in,\n",
            "\\IEEEauthorrefmark{4}shobhit.verma@spit.ac.in,\n",
            "\\IEEEauthorrefmark{5}sunil\\_ghane@spit.ac.in}}\n",
            "\n",
            "\\maketitle\n",
            "\n",
            "\\begin{abstract}\n",
            "India is the land of agriculture and is among the top three global producers of many crops. The Indian farmer lies at the heart of the agricultural sector yet most Indian farmers remain at the bottom of the social strata. In addition, farmers find it difficult to decide which crop is best suitable and profitable for their soil, in spite of the few technological solutions that exist today, due to the variation in soil types across geographical regions. This paper proposes a crop recommendation system that uses a Convolutional Neural Network (CNN) and a Random Forest Model to predict the optimal crop to be grown by analyzing various parameters including the region, soil type, yield, selling price, etc. The CNN architecture gave an accuracy of 95.21\\%, and the Random Forest Algorithm had an accuracy of 75\\%.\n",
            "\n",
            "\\end{abstract}\n",
            "\n",
            "\\begin{IEEEkeywords}\n",
            " Random Forest, Image classification, Deep learning, Convolutional Neural Network\n",
            "\\end{IEEEkeywords}\n",
            "\n",
            "\\section{\\colorbox{blue}{\\color{blue}INTRODUCTION}}\n",
            "\\colorbox{blue}{\\color{blue}Agriculture} \\colorbox{blue}{\\color{blue}has} \\colorbox{blue}{\\color{blue}historically} been and remains to this day one of the main pillars of the Indian economy as two-thirds of the Indian population is directly dependent on agriculture for their livelihood. An equally important fact is that it contributes to 20\\% of India’s Global Domestic Product (GDP). At the crux of the agriculture sector lies the farmer, the Annadatta (Food Provider) of our country, who is facing many adversities today:\n",
            "\\begin{enumerate}\n",
            "    \\item With the diversity in soil types across the country farmers usually find it difficult to decide which crop is best suitable and profitable to their soil, their conditions, their region, and hence end up facing many losses.  \n",
            "    \\item Presently it is extremely difficult for farmers to predict the yield for a particular sowing season and the profit that they can earn due to unpredictable weather conditions.\n",
            "    \\item Dismally low profits that farmers earn for their produce because of the 'farm to market' mechanism which involves hundreds of middlemen who eat up most of the profits by transporting and selling crops.\\newline\n",
            "\\end{enumerate}\\par\n",
            "Machine Learning and Artificial Intelligence find many applications in the modern agriculture industry. Techniques such as precision agriculture and crop recommender systems can be used to improve overall harvest quality, yield prediction, pest detection in plants and poor nutrition of farms. Deployment of AI systems can provide a shot in the arm to the beleaguered agricultural sector.\n",
            "\n",
            "India's current agricultural suffering casts serious doubt on the future of the sector. The agricultural sector contributes 20\\% of GDP by hiring almost two-thirds of the workforce. Nearly 85\\% of Indian farmers operate with less than 5 acres of land, undertake significant product and market risks every season and  are forced to rely on non-institutional credit sources due to a lack of collateral. Farmers with small holdings also account for 46\\% of cultivated land, half of the agricultural production, and a much higher share of high-value crops. But they are routinely excluded from modern market arrangements such as contract farming and direct purchases due to low literacy rates.\\newline\n",
            "\n",
            "This paper describes a soil analysis and crop prediction mechanism that uses a Convolutional Neural Network and Random Forest Algorithm to solve some of the long-standing problems of the Indian agricultural sector and increase profitability for the average farmer. Additionally, it details the design and implementation of a website that serves as a marketplace for farmers and potential crop buyers, hence eliminating the need for a middleman.\n",
            "The remainder of the paper is divided into 4 sections as follows:\n",
            "\\begin{enumerate}\n",
            "    \\item Section 2 details past work done in Crop Prediction and Soil Classification.\n",
            "    \\item Section 3 describes the flow of the proposed system and its implementation.\n",
            "    \\item Section 4 summarizes observations and results.\n",
            "    \\item Section 5 mentions the conclusion and future scope\n",
            "\\end{enumerate}\n",
            "\n",
            "\\section{background and related work}\n",
            "In this section, we review, summarize and analyze work related to Crop Prediction and Soil Classification in agriculture.\\newline\\break\n",
            "%==================================== 1 ========================================\n",
            " Babu et al. [1] described a model that applies Precision Agriculture (PA) principles to small, open farms at the individual farmer and crop level, to affect a degree of control over variability. The goal of the model was to recommend crops to even the smallest farmer at the level of his/her smallest plot of the crop, using the most accessible technologies such as SMS and email. The model was designed for the state of Kerala.\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 2 ========================================\n",
            "Pudumalar et al. [2] proposed a recommender system on precision agriculture using data mining techniques. Crop recommendation was based on the research data of their soil types, soil characteristics, and crop yield. Their system used an ensemble method using majority voting, consisting of four individual models, namely, CHAID, Random tree, Naive Bayes, and K-Nearest Neighbours. \n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 3 ========================================\n",
            "Rajak et al. [3] proposed an ensemble model with a majority voting technique, where the ensemble model comprises four individual models, namely, Support Vector Machine, Artificial Neural Network, Random Tree, and Naive Bayes. Their dataset included various attributes of soil like pH, water density, etc. as features collected from soil testing labs and universities.\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 4 ========================================\n",
            "Reddy et al. [4] proposed a two-step model - the first step for soil classification and a second step for crop suggestion. The first step used chemical features of soil such as moisture, the content of potassium, magnesium, etc. to predict the soil series or the soil type. The second step used features such as the soil series, temperature, humidity, rainfall, and pH. Classification algorithms like Support Vector Machine, K-Nearest Neighbours, and Bagging were utilized to suggest crops. Although this paper did not implement the system proposed by them, its’ two-step model inspired us to use different machine learning algorithms to achieve different goals of the system by using a two-step model.\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 5 ========================================\n",
            "Savla et al. [5] compared classification algorithms and their performance in yield prediction in precision agriculture. These algorithms were implemented on a data set collected for several years in yield prediction on the soya bean crop. The algorithms used were Support Vector Machine, Random Forest, Neural Network, REPTree, Bagging, and Bayes. The authors concluded that bagging was the best algorithm for yield prediction as the error deviation was minimum.\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 6 ========================================\n",
            "Manjula et al. [6] developed a framework called eXtensible Crop Yield Prediction Framework (XCYPF) that enabled the flexible inclusion of various techniques towards crop yield prediction. They also developed a tool that would help people to predict crop yield for various crops with dependent and independent variables. \n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 7 ========================================\n",
            "Kumar et al. [7] proposed a Crop Selection Method (CSM) to solve the crop selection problem and improve the net yield rate of the crop. The method suggested a series of crops to be selected over a season considering factors like weather, soil type, water density, and crop type. The predicted value of influential parameters determined the accuracy of the model. They also illustrated the significance of crop selection and the factors affecting crop selection like production rate, market price, and government policies.\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 7 ========================================\n",
            "Ahamed et al. [8] used data mining techniques to estimate the crop yield for cereal crops in major districts of Bangladesh. They proposed a system that consisted of two parts: Clustering (for creating district clusters) and Classification using KNN (k-nearest neighbor), Linear Regression, (ANN) artificial neural network in rapid miner tool. Their data set included 5 environmental variables, 3 biotic variables, and 2 area-related variables to determine the crop yield in different districts.\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 9 ========================================\n",
            "Paul et al. [9] analyzed soil datasets to predict soil categories/types. They identified crop yield from the predicted soil categories as a classification rule. Naive Bayes and K-nearest neighbor algorithms were used for predicting crop yields\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 10 ========================================\n",
            "Khedr et al. [10] tried to solve the problem of food insecurity in Egypt. They proposed a framework to predict the production, and import for a particular year. The model used Artificial Neural Networks along with Multi-layer perceptrons in WEKA to build the prediction. At the end of the process, one would be able to visualize the amount of production import, need, and availability. The goal was to make decisions on whether food needs to be imported or not. \n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 11 ========================================\n",
            "Venugopal et al. [11] used three machine learning algorithms i.e. Logistic Regression, Naive Bayes algorithm, and Random forest algorithm to recommend suitable crops and predict yield value and then compared the results of those algorithms. They collected past data on weather, temperature, and a number of other factors to train their models. The Random Forest Algorithm gave the highest accuracy among all those three algorithms.\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 12 ========================================\n",
            "Mahendra et al. [12] proposed a system that predicted the most suitable crop based on soil contents, soil PH, weather, and rainfall. They used a Support Vector Machine(SVM) algorithm for rainfall prediction. The result was used for crop prediction using the Decision Tree Algorithm.\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 13 ========================================\n",
            "Priya et al. [13] used Random Forest Algorithm to predict crop yield for the state of Tamil Nadu, India. Their model consisted of parameters like rainfall, maximum temperature, season, and production. \n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 14 ========================================\n",
            "Champaneri et al. [14] used Random Forest Algorithm for crop yield predictions for the state of Maharashtra. They gathered data from different government websites and data related to the climatic parameters (precipitation, temperature, cloud cover, vapor pressure) at a monthly level which was used to train a machine learning model.\\%.\n",
            "\\\\\n",
            "\\break\n",
            "% ==================================== 15 ========================================\n",
            "Bharath et al. [15] proposed a system to recommend the most suitable crops for a farmer based on nutritional features of land. These features would be calculated in a lab from a soil sample collected by the farmer. The Naive Bayes algorithm was used for prediction and the model's accuracy was 75\\%\n",
            "\\break\n",
            "\n",
            "\n",
            "The systems proposed by the above papers have a few drawbacks:\n",
            "\\begin{enumerate}\n",
            "    \\item References [1], [2], [3], [4], [5], [6] and [7] require site-specific features like chemical properties of the soil, such as the content of minerals, pH, etc and other properties such as wind speed which may be tough and/or expensive for farmer to collect.\n",
            "    \n",
            "    \\item References [1], [2], [4], [12] and [15] focus only on recommending crops that are best suited to the soil without considering their yield or gross revenue.\n",
            "\\end{enumerate}\n",
            "\n",
            "Thus trade-offs between quality and revenue are ignored which may have a great impact on income of the farmer. The proposed system recommends crops that are most appropriate for a given soil type and region simultaneously considering the revenue that the crops could potentially generate.\n",
            "\n",
            "\\section{Methodology}\n",
            "\n",
            "\n",
            "This section describes a two-step model solution based on machine learning. A user clicks a picture of soil, sets location and area parameters and feeds these inputs to the system. The output will be a list of crop recommendations based on predicted quality, quantity(yield), and gross revenue.\n",
            "\n",
            "\\subsection{System Overview}\\label{AA}\n",
            "\\begin{flushleft}\n",
            "Step 1: Soil Classification using Convolutional Neural Networks\n",
            "\\end{flushleft}\n",
            "\n",
            "\n",
            "In the first step, we process the image of the soil that is fed into the system by the user and classify it into one of the four classes of soil, namely Red, Alluvial, Black, and Clay. This is done by a Convolutional Neural Network whose implementation details are discussed in the following subsections. After the soil type is predicted, a few crops are shortlisted that are suitable to be cultivated in that soil type. Hence, this step ensures that the quality of the crops recommended is good, as only crops suitable to the soil type are shortlisted.\n",
            "\n",
            "\\begin{flushleft}\n",
            "Step 2: Yield and Income Prediction\n",
            "\\end{flushleft}\n",
            "In the second step, our system considers features such as soil type (predicted by the first step), Area of land to be cultivated (in hectares), State, District, crop, and season of cultivation and predicts the yield of all the shortlisted crops given the above features (in quintals). This is done by the Random Forest Algorithm whose implementation details are discussed in the following subsections. After the yield is predicted, the system uses an API developed by the Government of India [16] to retrieve the price of each crop in the shortlist in the given region. This is used to estimate the income generated by a crop using the unitary method. The crop which generates the highest income is then recommended to the user. Hence, this step takes into account the quantity and the profitability of the crop.\n",
            "\n",
            "\\begin{figure}[htbp]\n",
            "\\centerline{\\includegraphics[width=8cm, height=5cm]{overview.jpeg}}\n",
            "\\caption{System Workflow}\n",
            "\\label{fig}\n",
            "\\end{figure}\\break\n",
            "\n",
            "\\subsection{System Architecture}\n",
            "\n",
            "\n",
            "\\begin{flushleft}\n",
            "\\subsubsection{Convolutional Neural Network}\n",
            "\\end{flushleft}\n",
            "\\begin{figure}[htbp]\n",
            "\\centerline{\\includegraphics[width=8cm, height=5cm]{cnn1.jpeg}}\n",
            "\\caption{CNN Network Architecture}\n",
            "\\label{fig}\n",
            "\\end{figure}\n",
            "i) Dataset Collection:\\newline\n",
            "\\\\\n",
            "The dataset used in training the parameters of this algorithm comprises images of the different soil types namely, Red Soil, Black Soil, Clay Soil, and Alluvial Soil. The dataset includes 150-200 images of each soil type in the training set and about 50 images in the test set. This data is collected from the Soil Classification Image Dataset [17] on Kaggle and from similar other online sources.\\newline\\break\n",
            "ii) Data Pre-Processing and Algorithm Implementation:\\newline\n",
            "\\\\\n",
            "The images in the dataset are of various sizes and dimensions, and hence need to be resized and pre-processed before they are fed into the model. The algorithm needs to read a colored image for our use case, and every colored image in RGB format has three channels, one for each color, Red, Green, and Blue. Hence, the images are first resized to 300x300x3 images. The images are then converted into numerical (pixel intensities) arrays so that the model can process the data. This numerical data is then fed into the Machine Learning model.\\newline\n",
            "The machine learning model used to classify these images into the different soil types is a Convolutional Neural Network. The network architecture of the same can be seen in Fig 2.\\newline\n",
            "\n",
            "\n",
            "\n",
            "The network contains 9 layers, with 7 convolutional+pooling layers followed by 2 fully connected layers which includes 1 softmax layer. Each convolutional layer has filter size(f) =3, stride (s)=1 and padding (p)=0. Max-pooling is used in all the pooling layers with filter/kernel size(f) =3, and stride (s)=1. The convolutional layers and one fully connected layer use the ReLU activation function. Hence, the network contains 2,365,636 trainable parameters. This network was trained with the Adam Optimization Algorithm and with the learning rate set to  10\\^ -3 for 20 epochs. The model gave an accuracy of 95.21\\% on the test set. The training results can for this model can be seen in the Accuracy and Loss graphs in Fig 3 and Fig 4 respectively.\n",
            "\n",
            "% ================ TO ADD IMAGE =======================\n",
            "\\begin{figure}[htbp]\n",
            "\\centerline{\\includegraphics[width=8cm, height=5cm]{Accuracyconv.PNG}}\n",
            "\\caption{Graph of Accuracy of CNN Vs No. of Training Steps}\n",
            "\\label{fig}\n",
            "\\end{figure}\n",
            "% ================ IMAGE =======================\n",
            "\n",
            "% ================ TO ADD IMAGE =======================\n",
            "\\begin{figure}[htbp]\n",
            "\\centerline{\\includegraphics[width=8cm, height=5cm]{lossconvFinal.PNG}}\n",
            "\\caption{Graph of Loss Function of CNN Vs No. of Training Steps}\n",
            "\\label{fig}\n",
            "\\end{figure}\n",
            "% ================ IMAGE =======================\n",
            "\n",
            "\n",
            "\n",
            "\\begin{flushleft}\n",
            "\\subsubsection{Random Forest Algorithm}\n",
            "\\end{flushleft}\n",
            "i) Dataset Collection:\\newline\n",
            "\\\\\n",
            "The dataset used in training the parameters of this algorithm is used to predict the yield of a particular crop in a region, and hence it comprises features such as the State, District, Season of Cultivation, Crop, the Area of the land to be cultivated, and the yield of the crop. This data is collected from the Crop Prediction in India [18] dataset on Kaggle and other online sources such as news articles.\\newline\\break\n",
            "\n",
            "ii) Data Pre-Processing and Algorithm Implementation:\\newline\n",
            "\\\\\n",
            "This dataset contains dirty data, hence our first pre-processing step was to clean the data, we did this by removing entries/rows with one or more missing/null values. Our dataset also contains categorical string data, which needs to be encoded in numeric form so that the Random Forest algorithm can process it. Hence, our second step was to encode categorical string data using One-Hot Encoding.\\newline\\break\n",
            "Using the One-Hot Encoding method, all unique values from a single column were considered as a separate feature. The dataset had 124 unique values of crops, 6 unique values of Seasons, 33 unique values of States, so a total of 164 features with Area. Suppose we have to provide Coconut as input to the model, then the column name Coconut will be set to 1 and the rest of the columns having crop names will be set to 0. The same applies to states and seasons.\\newline\\break\n",
            "Random Forest builds multiple decision trees and combines them together by using a bagging method, which selects a random sample of data from a training set. As a result for a dataset that requires such robust features a Random Forest Algorithm works best and better than many other regression methods like Linear Regression. Random Forest gave a 75.67\\% score. The numeric output of yield was predicted best by Random Forest and the end result matched for many crops of different states.\n",
            "\n",
            "\\subsection{Web Portal}\n",
            "To assimilate all the components of the system we have discussed so far, we decide to create a prototype of a web portal that would use the Crop Recommendation System proposed by this paper. This portal has a very attractive, and user-friendly, user interface. This web portal can be used by two types of users, farmers, and wholesalers. Farmers can feed in the inputs of the two models of the system and get crop recommendations based on those inputs. Once a farmer decides to grow a crop, he/she can create a crop listing on the “Farmer’s Market” section of the portal. Wholesalers can view these listings on the “Farmer’s Market” section and can send requests to connect with the farmer of their choice to continue further dealings. Once the farmer accepts the request, then the farmer and wholesaler can reach out to each other using the WhatsApp feature of the portal and continue their dealings. This feature of the portal solves the middleman problem so that a farmer can keep the entirety of his profits. Snapshots of the Recommendation feature and the 'Farmer's Market' section can be seen in Fig 5 and Fig 6 respectively.\n",
            "\n",
            "% ================ TO ADD IMAGE =======================\n",
            "\\begin{figure}[htbp]\n",
            "\\centerline{\\includegraphics[width=8cm, height=5cm]{predic.png}}\n",
            "\\caption{Recommendation System on the Web Portal}\n",
            "\\label{fig}\n",
            "\\end{figure}\n",
            "% ================ IMAGE =======================\n",
            "\n",
            "% ================ TO ADD IMAGE =======================\n",
            "\\begin{figure}[htbp]\n",
            "\\centerline{\\includegraphics[width=8cm, height=5cm]{farmermarket.png}}\n",
            "\\caption{Farmer's Market Section on the Web Portal}\n",
            "\\label{fig}\n",
            "\\end{figure}\n",
            "% ================ IMAGE =======================\n",
            "\n",
            "\n",
            "% ================ TO ADD IMAGE =======================\n",
            "\\definecolor{my_magenta}{HTML}{FF00FF}\n",
            "\\begin{figure}[htbp]\n",
            "\\centerline{\\includegraphics[cfbox=my_magenta 1pt 1pt,width=8cm, height=5cm]{alexnet.jpeg}}\n",
            "\\caption{Alexnet Network Architecture}\n",
            "\\label{fig}\n",
            "\\end{figure}\n",
            "% ================ IMAGE =======================\n",
            "\\section{OBSERVATIONS AND RESULTS}\n",
            "This section describes the various image classification algorithms and architectures we experimented with and how they compare with each other.\n",
            "\n",
            "\\subsection{Support Vector Machine (SVM)}\n",
            "\n",
            "For this algorithm, the images are first resized to 200 x 200 x 3 images. The images are then converted into numerical (pixel intensities) arrays and then flattened to a 120000 x 1 feature vector. This feature vector is then fed into the SVM model. The SVM model was trained using two kernels, namely the linear and the Radial Basis Function(RBF) Kernel. The model with a linear kernel gave an accuracy of 83.5\\% and the RBF kernel gave an accuracy of 86.7\\% on the test set.\n",
            "\n",
            "\\subsection{AlexNet}\n",
            "\n",
            "This is a classical network architecture for the Convolutional Neural Network Algorithm, this architecture was proposed in the paper [19]. To replicate the dimensions for this architecture the images were first resized to 224 x 224 x 3 images. The images are then converted into numerical (pixel intensities) arrays, this numerical data is then fed into the CNN model. This architecture can be observed in Figure 3.\n",
            "\\newline\n",
            "We implemented the exact architecture suggested by the paper [19] with just a minor modification in the output layer, where we have 4 units as opposed to 1000 units since we have only 4 classes. Hence, the network contains about 59 million trainable parameters. The model was trained using the Adam Optimization Algorithm with the learning rate as 10\\^-3 and epoch as 25. This architecture gave us an accuracy of 25\\% on the test set.\n",
            "\n",
            "\\subsection{Convolutional Neural Networks with Other/New Architectures}\n",
            "\n",
            "After getting decent results from the SVM model and disappointing results from AlexNet, we decided to experiment with different architectures in the CNN algorithm. For all the following architectures the images are first resized to 300x300x3 images. The images are then converted into numerical (pixel intensities) arrays, which is then fed into the CNN model. The model is trained using the Adam optimization algorithm with learning rate for all architectures as 10\\^-4 and no. of epochs as 25. \n",
            "\n",
            "\\begin{flushleft}\n",
            "\\subsubsection{32-64-128-64-32 Architecture}\n",
            "\\end{flushleft}\n",
            "In this architecture there are 7 layers with 5 convolutional + pooling layers, of sizes 32,64,128,64, and 32, with ReLu activation, followed by one fully connected layer of size 1024, with ReLu activation and one fully connected layer of size 104, with softmax activation. The filter size was kept the same for all convolutional and max-pooling layers. We experimented with three filter sizes, the accuracy obtained in each case is summarized in Table 1.\n",
            "% ================ TO ADD TABLE =======================\n",
            "\\begin{table}[htbp]\n",
            "\\caption{Comparison between filter sizes in the 32-64-128-64-32 architecture}\n",
            "\\begin{center}\n",
            "\\begin{tabular}{ |p{2cm}|p{2cm}|p{2cm}|p{2cm}|  }\n",
            " \\hline\n",
            "%  \\multicolumn{2}{|c|}{Comparison} \\\\\n",
            " Filter Size & Accuracy \\\\\n",
            " \\hline\n",
            " f=3  &  88.75\\%\\\\\n",
            " \\hline\n",
            " f=5  &  87\\% \\\\\n",
            " \\hline\n",
            " f=7 &  82.44\\%\\\\\n",
            " \\hline\n",
            "\\end{tabular}\n",
            "\\end{center}\n",
            "\\end{table}\n",
            "% ================ TABLE =======================\n",
            "\n",
            "\\begin{flushleft}\n",
            "\\subsubsection{64-128-256-128-64 Architecture}\n",
            "\\end{flushleft}\n",
            " \n",
            "\n",
            "In this architecture there are 7 layers with 5 convolutional + pooling layers, of sizes 64,128,256,128 and 64, with ReLu activation, followed by one fully connected layer of size 1024, with ReLu activation and one fully connected layer of size 4, with softmax activation. The filter size was kept the same for all convolutional and max-pooling layers. We experimented with three filter sizes, the accuracy obtained in each case is summarized in Table 2.\n",
            "% ================ TO ADD TABLE =======================\n",
            "\\begin{table}[htbp]\n",
            "\\caption{Comparison between filter sizes in the 64-128-256-128-64 architecture}\n",
            "\\begin{center}\n",
            "\\begin{tabular}{ |p{2cm}|p{2cm}|p{2cm}|p{2cm}|  }\n",
            " \\hline\n",
            "%  \\multicolumn{2}{|c|}{Comparison} \\\\\n",
            " Filter Size & Accuracy \\\\\n",
            " \\hline\n",
            " f=3 & 25\\% \\\\\n",
            " \\hline\n",
            " f=5 & 90.95\\% \\\\\n",
            " \\hline\n",
            " f=7 & 79.2\\% \\\\\n",
            " \\hline\n",
            "\\end{tabular}\n",
            "\\end{center}\n",
            "\\end{table}\n",
            "% ================ TABLE =======================\n",
            "\n",
            "\n",
            "\\begin{flushleft}\n",
            "\\subsubsection{64-128-32-64-32-128-64 Architecture} \n",
            "\\end{flushleft}\n",
            "In this architecture there are 9 layers with 7 convolutional + pooling layers, of sizes 64,128,32,64,32,128 and 64, with ReLu activation, followed by one fully connected layer of size 1024, with ReLu activation and one fully connected layer of size 4, with softmax activation. The filter size was kept the same for all convolutional and max-pooling layers. We experimented with three filter sizes, the accuracy obtained in each case is summarized in Table 3:\n",
            "% ================ TO ADD TABLE =======================\n",
            "\\begin{table}[htbp]\n",
            "\\caption{Comparison between filter sizes in the 64-128-32-64-32-128-64 architecture}\n",
            "\\begin{center}\n",
            "\\begin{tabular}{ |p{2cm}|p{2cm}|p{2cm}|p{2cm}|  }\n",
            " \\hline\n",
            "%  \\multicolumn{2}{|c|}{Comparison} \\\\\n",
            " Filter Size & Accuracy \\\\\n",
            " \\hline\n",
            " f=3 & 81.38\\%\\\\\n",
            " \\hline\n",
            " f=5 & 95.21\\%\\\\\n",
            " \\hline\n",
            " f=7 & 69.68\\%\\\\\n",
            " \\hline\n",
            "\\end{tabular}\n",
            "\\end{center}\n",
            "\\end{table}\n",
            "% ================ TABLE =======================\n",
            "\n",
            "The results of all algorithms are summarized in the table 4.\n",
            "\n",
            "% ================ TO ADD TABLE =======================\n",
            "\\begin{table}[htbp]\n",
            "\\caption{Comparison between various algorithms and architectures}\n",
            "\\begin{center}\n",
            "\\begin{tabular}{ |p{0.25cm}|p{1.5cm}|p{2.6cm}|p{1.3cm}|p{0.9cm}|  }\n",
            " \\hline\n",
            "%  \\multicolumn{2}{|c|}{Comparison} \\\\\n",
            " Sr. No. & Algorithm /Architecture & Hyperparamters & No. of trainable parameters & Accuracy \\\\\n",
            " \\hline\n",
            "1 & SVM & RBF Kernel & 120,000 & 86.7\\%\\\\\n",
            "\\hline\n",
            "2 & AlexNet & Adam, Learning Rate=10^{-3},    Epochs = 25 & 59 Million & 25\\%\\\\\n",
            " \\hline\n",
            "3 & CNN (32-64-128-64-32) & Adam, Learning Rate=10^{-4}, Epochs = 25, f=5 & 1.33 Million & 87\\%\\\\\n",
            " \\hline\n",
            " 4 & CNN (64-128-256-128-64) & Adam, Learning Rate=10^{-3}, Epochs = 25, f=5 & 3.7 Million & 90.95\\%\\\\\n",
            " \\hline\n",
            " 5 & CNN (64-128-32-64-32-128-64) & Adam, Learning Rate=10^{-3}, Epochs = 25, f=5 & 2.3 Million & 95.21\\%\\\\\n",
            "\\hline\n",
            "\n",
            "\n",
            "\\end{tabular}\n",
            "\\end{center}\n",
            "\\end{table}\n",
            "% ================ TABLE =======================\n",
            "% \\begin{tabular}{ |p{1.75cm}||p{1.75cm}|p{1.75cm}|p{1.75cm}|  }\n",
            "%  \\hline\n",
            "%  \\multicolumn{4}{|c|}{Country List} \\\\\n",
            "%  \\hline\n",
            "%  Algorithm/Architecture & Hyperparamters  & No. of trainable parameters & Accuracy\\\\\n",
            "%  \\hline\n",
            "%  SVM   & RBF Kernel    &120,000&   86.7\\%\\\\\n",
            "%  AlexNet&   Adam, Learning Rate=10^-3, Epochs = 25  & 59 Million   & 25\\%\\\\\n",
            "%  CNN (32-64-128-64-32) &Adam, Learning Rate=10^-4, Epochs = 25, f=5 & 1.33 Million&  87\\%\\\\\n",
            "%  CNN (64-128-256-128-64)    &Adam, Learning Rate=10^-3, Epochs = 25, f=5 & 3.7 Million &  90.95\\%\\\\\n",
            "%  CNN (64-128-32-64-32-128-64) &   Adam, Learning Rate=10^-3, Epochs = 25, f=5  & 2.3 Million & 95.21\\%\\\\\n",
            "%  \\hline\n",
            "% \\end{tabular}\n",
            "\n",
            "% ==================================== Conclusion ========================================\n",
            "\\section{Conclusion and Future Scope}\n",
            "\n",
            "A flourishing agricultural sector is key for India's sustained economic growth. Our aim was to empower farmers with small land holdings by increasing profitability and maximising crop yield. In our experiments Convolutional Neural Networks with symmetrical architectures gave significantly better results for image classification for the selected soil classification dataset. The final CNN architecture had an amazing accuracy of 95.21\\%. The Random Forest Algorithm had an accuracy of 75\\%.\n",
            "Future experiments can adapt this system to a mixture of soil types, by accounting for the composition present in the minority of the mixture. The system can be further improved by expanding the crop production dataset to get more accurate results for yield prediction\\newline\\break\n",
            "\n",
            "\n",
            "% \\subsection{\\LaTeX-Specific Advice}\n",
            "\n",
            "% Please use ``soft'' (e.g., \\verb|\\eqref{Eq}|) cross references instead\n",
            "% of ``hard'' references (e.g., \\verb|(1)|). That will make it possible\n",
            "% to combine sections, add equations, or change the order of figures or\n",
            "% citations without having to go through the file line by line.\n",
            "\n",
            "% Please don't use the \\verb|{eqnarray}| equation environment. Use\n",
            "% \\verb|{align}| or \\verb|{IEEEeqnarray}| instead. The \\verb|{eqnarray}|\n",
            "% environment leaves unsightly spaces around relation symbols.\n",
            "\n",
            "% Please note that the \\verb|{subequations}| environment in {\\LaTeX}\n",
            "% will increment the main equation counter even when there are no\n",
            "% equation numbers displayed. If you forget that, you might write an\n",
            "% article in which the equation numbers skip from (17) to (20), causing\n",
            "% the copy editors to wonder if you've discovered a new method of\n",
            "% counting.\n",
            "\n",
            "% {\\BibTeX} does not work by magic. It doesn't get the bibliographic\n",
            "% data from thin air but from .bib files. If you use {\\BibTeX} to produce a\n",
            "% bibliography you must send the .bib files. \n",
            "\n",
            "% {\\LaTeX} can't read your mind. If you assign the same label to a\n",
            "% subsubsection and a table, you might find that Table I has been cross\n",
            "% referenced as Table IV-B3. \n",
            "\n",
            "% {\\LaTeX} does not have precognitive abilities. If you put a\n",
            "% \\verb|\\label| command before the command that updates the counter it's\n",
            "% supposed to be using, the label will pick up the last counter to be\n",
            "% cross referenced instead. In particular, a \\verb|\\label| command\n",
            "% should not go before the caption of a figure or a table.\n",
            "\n",
            "% Do not use \\verb|\\nonumber| inside the \\verb|{array}| environment. It\n",
            "% will not stop equation numbers inside \\verb|{array}| (there won't be\n",
            "% any anyway) and it might stop a wanted equation number in the\n",
            "% surrounding equation.\n",
            "\n",
            "% \\subsection{Some Common Mistakes}\\label{SCM}\n",
            "% \\begin{itemize}\n",
            "% \\item The word ``data'' is plural, not singular.\n",
            "% \\item The subscript for the permeability of vacuum $\\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.\n",
            "% \\item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)\n",
            "% \\item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).\n",
            "% \\item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.\n",
            "% \\item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.\n",
            "% \\item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.\n",
            "% \\item Do not confuse ``imply'' and ``infer''.\n",
            "% \\item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.\n",
            "% \\item There is no period after the ``et'' in the Latin abbreviation ``et al.''.\n",
            "% \\item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.\n",
            "% \\end{itemize}\n",
            "% An excellent style manual for science writers is \\cite{b7}.\n",
            "\n",
            "% \\subsection{Authors and Affiliations}\n",
            "% \\textbf{The class file is designed for, but not limited to, six authors.} A \n",
            "% minimum of one author is required for all conference articles. Author names \n",
            "% should be listed starting from left to right and then moving down to the \n",
            "% next line. This is the author sequence that will be used in future citations \n",
            "% and by indexing services. Names should not be listed in columns nor group by \n",
            "% affiliation. Please keep your affiliations as succinct as possible (for \n",
            "% example, do not differentiate among departments of the same organization).\n",
            "\n",
            "% \\subsection{Identify the Headings}\n",
            "% Headings, or heads, are organizational devices that guide the reader through \n",
            "% your paper. There are two types: component heads and text heads.\n",
            "\n",
            "% Component heads identify the different components of your paper and are not \n",
            "% topically subordinate to each other. Examples include Acknowledgments and \n",
            "% References and, for these, the correct style to use is ``Heading 5''. Use \n",
            "% ``figure caption'' for your Figure captions, and ``table head'' for your \n",
            "% table title. Run-in heads, such as ``Abstract'', will require you to apply a \n",
            "% style (in this case, italic) in addition to the style provided by the drop \n",
            "% down menu to differentiate the head from the text.\n",
            "\n",
            "% Text heads organize the topics on a relational, hierarchical basis. For \n",
            "% example, the paper title is the primary text head because all subsequent \n",
            "% material relates and elaborates on this one topic. If there are two or more \n",
            "% sub-topics, the next level head (uppercase Roman numerals) should be used \n",
            "% and, conversely, if there are not at least two sub-topics, then no subheads \n",
            "% should be introduced.\n",
            "\n",
            "% \\subsection{Figures and Tables}\n",
            "% \\paragraph{Positioning Figures and Tables} Place figures and tables at the top and \n",
            "% bottom of columns. Avoid placing them in the middle of columns. Large \n",
            "% figures and tables may span across both columns. Figure captions should be \n",
            "% below the figures; table heads should appear above the tables. Insert \n",
            "% figures and tables after they are cited in the text. Use the abbreviation \n",
            "% ``Fig.~\\ref{fig}'', even at the beginning of a sentence.\n",
            "\n",
            "% \\begin{table}[htbp]\n",
            "% \\caption{Table Type Styles}\n",
            "% \\begin{center}\n",
            "% \\begin{tabular}{|c|c|c|c|}\n",
            "% \\hline\n",
            "% \\textbf{Table}&\\multicolumn{3}{|c|}{\\textbf{Table Column Head}} \\\\\n",
            "% \\cline{2-4} \n",
            "% \\textbf{Head} & \\textbf{\\textit{Table column subhead}}& \\textbf{\\textit{Subhead}}& \\textbf{\\textit{Subhead}} \\\\\n",
            "% \\hline\n",
            "% copy& More table copy$^{\\mathrm{a}}$& &  \\\\\n",
            "% \\hline\n",
            "% \\multicolumn{4}{l}{$^{\\mathrm{a}}$Sample of a Table footnote.}\n",
            "% \\end{tabular}\n",
            "% \\label{tab1}\n",
            "% \\end{center}\n",
            "% \\end{table}\n",
            "\n",
            "% \\begin{figure}[htbp]\n",
            "% \\centerline{\\includegraphics{fig1.png}}\n",
            "% \\caption{Example of a figure caption.}\n",
            "% \\label{fig}\n",
            "% \\end{figure}\n",
            "\n",
            "% Figure Labels: Use 8 point Times New Roman for Figure labels. Use words \n",
            "% rather than symbols or abbreviations when writing Figure axis labels to \n",
            "% avoid confusing the reader. As an example, write the quantity \n",
            "% ``Magnetization'', or ``Magnetization, M'', not just ``M''. If including \n",
            "% units in the label, present them within parentheses. Do not label axes only \n",
            "% with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization \n",
            "% \\{A[m(1)]\\}'', not just ``A/m''. Do not label axes with a ratio of \n",
            "% quantities and units. For example, write ``Temperature (K)'', not \n",
            "% ``Temperature/K''.\n",
            "\n",
            "% \\section*{Acknowledgment}\n",
            "\n",
            "% The preferred spelling of the word ``acknowledgment'' in America is without \n",
            "% an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. \n",
            "% G.) thanks $\\ldots$''. Instead, try ``R. B. G. thanks$\\ldots$''. Put sponsor \n",
            "% acknowledgments in the unnumbered footnote on the first page.\n",
            "\n",
            "% \\section*{References}\n",
            "\n",
            "% Please number citations consecutively within brackets \\cite{b1}. The \n",
            "% sentence punctuation follows the bracket \\cite{b2}. Refer simply to the reference \n",
            "% number, as in \\cite{b3}---do not use ``Ref. \\cite{b3}'' or ``reference \\cite{b3}'' except at \n",
            "% the beginning of a sentence: ``Reference \\cite{b3} was the first $\\ldots$''\n",
            "\n",
            "% Number footnotes separately in superscripts. Place the actual footnote at \n",
            "% the bottom of the column in which it was cited. Do not put footnotes in the \n",
            "% abstract or reference list. Use letters for table footnotes.\n",
            "\n",
            "% Unless there are six authors or more give all authors' names; do not use \n",
            "% ``et al.''. Papers that have not been published, even if they have been \n",
            "% submitted for publication, should be cited as ``unpublished'' \\cite{b4}. Papers \n",
            "% that have been accepted for publication should be cited as ``in press'' \\cite{b5}. \n",
            "% Capitalize only the first word in a paper title, except for proper nouns and \n",
            "% element symbols.\n",
            "\n",
            "% For papers published in translation journals, please give the English \n",
            "% citation first, followed by the original foreign-language citation \\cite{b6}.\n",
            "\n",
            "\\begin{thebibliography}{00}\n",
            "\\bibitem{b1} S. Babu, \\q{A software model for precision agriculture for small and marginal farmers,}  in \\textit{Proc. 2013 IEEE Global Humanitarian Technology Conference: South Asia Satellite}, pp. 352-355, doi: 10.1109/GHTC-SAS.2013.6629944. \n",
            "\n",
            "\\bibitem{b2} S. Pudumalar et al., \\q{Crop recommendation system for precision agriculture,} in \\textit{Proc. 2016 Eighth Int. Conf. Adv. Comput},  pp. 32-36, doi:10.1109/ICoAC.2017.7951740\n",
            "    \n",
            "\\bibitem{b3} R. K. Rajak et al.,\\q{Crop Recommendation System to Maximize Crop Yield using Machine Learning Technique,} \\textit{Int. Res. J. of Eng. and Technol}., issue 12, vol. 4, pp. 950-953, Dec 2017 \n",
            "\n",
            "\\bibitem{b4} A.K.M. Reddy, S. Chithra, H.M. Hemashree and Thanu K.,   \\q{Soil Classification and Crop Suggestion using Machine Learning,}  \\textit{Int. J. for Res. in Appl. Sci. and Eng. Technol.}, issue 7, vol. 8, pp. 1625-1628, Jul 2020\n",
            "\n",
            "\\bibitem{b5}  A. Savla et al., \\q{Survey of classification algorithms for formulating yield prediction accuracy in precision agriculture,} in \\textit{Proc. 2015 Int. Conf. Innov. in Inf., Embedded and Commun. Syst.}, pp. 1-7, doi:10.1109/ICIIECS.2015.7193120\n",
            "\n",
            "\\bibitem{b6}  A. Manjula and  G. Narsimha, \\q{XCYPF: A Flexible and Extensible Framework for Agricultural Crop Yield Prediction,} in \\textit{Proc. 2015 Conf. Intell. Syst. and Control}, pp. 1-5, doi:10.1109/ISCO.2015.7282311 \n",
            "\n",
            "\\bibitem{b7} R. Kumar, M.P. Singh, P. Kumar and J.P. Singh, \\q{ Crop Selection Method to Maximize Crop Yield Rate using Machine Learning Technique,} in \\textit{Proc. 2015 Int. Conf.  Smart Technol. and Manage. for Comput., Commun., Controls, Energy and Mater.}, pp. 138-145, doi: 10.1109/ICSTM.2015.7225403 \n",
            "\n",
            "\\bibitem{b8} A. T. M. S. Ahamed et al., \\q{Applying data mining techniques to predict annual yield of major crops and recommend planting different crops in different districts in Bangladesh,} in \\textit{Proc. 2015 IEEE/ACIS 16th Int. Conf. Soft. Eng., Artif. Intell., Netw. and Parallel/Distrib. Comput.}, pp. 1-6, doi: 10.1109/SNPD.2015.7176185\n",
            "\n",
            "\\bibitem{b9} M. Paul, S.K. Vishwakarma and A. Verma, \\q{Analysis of Soil Behaviour and Prediction of Crop Yield using Data Mining Approach,} in \\textit{Proc. 2015 Int. Conf. Comput. Intell. and Commun. Netw.,} pp. 766-771, doi: 10.1109/CICN.2015.156.\n",
            "\n",
            "\\bibitem{b10} A.E. Khedr, M. Kadry and G. Walid, \\q{Proposed Framework for Implementing Data Mining Techniques to Enhance Decisions in Agriculture Sector Applied Case on Food Security Information Center Ministry of Agriculture, Egypt,} \\textit{Procedia Comput. Sci.}, issue 25, vol. 65, pp. 633-642, 2015\n",
            "\n",
            "\\bibitem{b11} A. Venugopal, S. Aparna, J. Mani, R. Matthew. and V. Williams, \\q{Crop Yield Prediction using Machine Learning Algorithms,}  \\textit{Int. J. of Eng. Res. and Technol.}, issue 13, vol. 9, pp. 87-91, Aug 2021\n",
            "\n",
            "\\bibitem{b12}  Mahendra N. , Dhanush V., Nischitha K., Ashwini and Manjuraju M. R, \\q{Crop Prediction using Machine Learning Approaches,}  \\textit{Int. J. of Eng. Res and Technol.},  issue 8, vol. 9, pp. 23-26, Aug 2020 \n",
            "\n",
            "\\bibitem{b13} Priya P., Muthaiah U. and Balamurugan M., \\q{Predicting Yield of the Crop Using Machine Learning Algorithm,} \\textit{Int. J. of Eng. Sci and Res. Technol.}, issue 11,vol. 29, pp. 1248-1255, 2020  \n",
            "\n",
            "\\bibitem{b14} M. Champaneri, D. Chachpara, C. Chandvidkar and M. Rathod, \\q{Crop Yield Prediction using Machine Learning,} \\textit{Int. J. of Sci. and Res.}, issue 1, vol. 10, pp. 01-03, Apr 2018\n",
            "\n",
            "\\bibitem{b15} Bharath K.R., Balakrishna K., Bency C.A.., Siddesha M. and Sushmitha R., \\q{Crop Recommendation System for Precision Agriculture,} \\textit{Int. J. of Comput. Sci. and Eng.}, issue 5, vol. 7, pp. 1277-1282, May 2019\n",
            "\n",
            "\\bibitem{b16} Kaggle, \\q{Soil-Type-Classification for Crops Suggestion,} Accessed: Feb 2021. [Online]. Available:\n",
            "https://www.kaggle.com/omkargurav/soil-classification-image-data\n",
            "\n",
            "\n",
            "\\bibitem{b17} Kaggle, \\q{Crop Production in India,} Accessed: Feb 2021. [Online] . Available: https://www.kaggle.com/abhinand05/crop-production-in-india\n",
            "\n",
            "\\bibitem{b18}  Open Government Data(OGD) Platform India, \\q{Current Daily Price of Various Commodities from Various Markets (Mandi),} Accessed: Feb 2021. [Online] . Available: \n",
            "https://data.gov.in/resources/current-daily-price-various-commodities-various-markets-mandi/\n",
            "\n",
            "\n",
            "\\bibitem{b19} A. Krizhevsky, I. Sutskever and G.E. Hinton, \\q{ImageNet classification with deep convolutional neural networks,} in\\textit{ Proc. 25th Int. Conf. on Neural Information Processing Systems}, Curran Associates Inc., Red Hook, NY, USA, 2012, pp. 1097–1105, doi:10.1145/3065386\n",
            "\n",
            "\\end{thebibliography}\n",
            "\\vspace{12pt}\n",
            "\n",
            "\\end{document}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def colorit(strings, color):\n",
        "  new_strings=[]\n",
        "  for string in strings:\n",
        "    string1=\"\"\n",
        "    for i in str(string).split():\n",
        "      if i!=\"\\n\":\n",
        "        string1+=\"{\\colorbox{\"+color+\"}{\\color{\"+color+\"}\"+i+\"}} \"\n",
        "      else:\n",
        "        string1+=\"\\n \"\n",
        "\n",
        "    print(string1)\n",
        "    new_strings.append(string1)\n",
        "  return new_strings"
      ],
      "metadata": {
        "id": "7_y7xGUCqvl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def string_colorit(string, color):\n",
        "  string1=\"\"\n",
        "  for i in str(string).split():\n",
        "    if i!=\"\\n\":\n",
        "      string1+=\"{\\colorbox{\"+color+\"}{\\color{\"+color+\"}\"+i+\"}} \"\n",
        "    else:\n",
        "      string1+=\"\\n \"\n",
        "\n",
        "  # print(string1)\n",
        "  return string1"
      ],
      "metadata": {
        "id": "LGL2dDbEL4L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Title\n",
        "toc.title.args[0].string=string_colorit(str(toc.title.args[0]),\"cyan\")"
      ],
      "metadata": {
        "id": "tWMZgvsR5FIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abstract\n",
        "toc.abstract.contents=colorit(list(toc.abstract.contents),\"pink\")"
      ],
      "metadata": {
        "id": "LrErx7UYh7qn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3aa9fc-c295-441a-c719-c90f8590dca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\\colorbox{pink}{\\color{pink}India}} {\\colorbox{pink}{\\color{pink}is}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}land}} {\\colorbox{pink}{\\color{pink}of}} {\\colorbox{pink}{\\color{pink}agriculture}} {\\colorbox{pink}{\\color{pink}and}} {\\colorbox{pink}{\\color{pink}is}} {\\colorbox{pink}{\\color{pink}among}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}top}} {\\colorbox{pink}{\\color{pink}three}} {\\colorbox{pink}{\\color{pink}global}} {\\colorbox{pink}{\\color{pink}producers}} {\\colorbox{pink}{\\color{pink}of}} {\\colorbox{pink}{\\color{pink}many}} {\\colorbox{pink}{\\color{pink}crops.}} {\\colorbox{pink}{\\color{pink}The}} {\\colorbox{pink}{\\color{pink}Indian}} {\\colorbox{pink}{\\color{pink}farmer}} {\\colorbox{pink}{\\color{pink}lies}} {\\colorbox{pink}{\\color{pink}at}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}heart}} {\\colorbox{pink}{\\color{pink}of}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}agricultural}} {\\colorbox{pink}{\\color{pink}sector}} {\\colorbox{pink}{\\color{pink}yet}} {\\colorbox{pink}{\\color{pink}most}} {\\colorbox{pink}{\\color{pink}Indian}} {\\colorbox{pink}{\\color{pink}farmers}} {\\colorbox{pink}{\\color{pink}remain}} {\\colorbox{pink}{\\color{pink}at}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}bottom}} {\\colorbox{pink}{\\color{pink}of}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}social}} {\\colorbox{pink}{\\color{pink}strata.}} {\\colorbox{pink}{\\color{pink}In}} {\\colorbox{pink}{\\color{pink}addition,}} {\\colorbox{pink}{\\color{pink}farmers}} {\\colorbox{pink}{\\color{pink}find}} {\\colorbox{pink}{\\color{pink}it}} {\\colorbox{pink}{\\color{pink}difficult}} {\\colorbox{pink}{\\color{pink}to}} {\\colorbox{pink}{\\color{pink}decide}} {\\colorbox{pink}{\\color{pink}which}} {\\colorbox{pink}{\\color{pink}crop}} {\\colorbox{pink}{\\color{pink}is}} {\\colorbox{pink}{\\color{pink}best}} {\\colorbox{pink}{\\color{pink}suitable}} {\\colorbox{pink}{\\color{pink}and}} {\\colorbox{pink}{\\color{pink}profitable}} {\\colorbox{pink}{\\color{pink}for}} {\\colorbox{pink}{\\color{pink}their}} {\\colorbox{pink}{\\color{pink}soil,}} {\\colorbox{pink}{\\color{pink}in}} {\\colorbox{pink}{\\color{pink}spite}} {\\colorbox{pink}{\\color{pink}of}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}few}} {\\colorbox{pink}{\\color{pink}technological}} {\\colorbox{pink}{\\color{pink}solutions}} {\\colorbox{pink}{\\color{pink}that}} {\\colorbox{pink}{\\color{pink}exist}} {\\colorbox{pink}{\\color{pink}today,}} {\\colorbox{pink}{\\color{pink}due}} {\\colorbox{pink}{\\color{pink}to}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}variation}} {\\colorbox{pink}{\\color{pink}in}} {\\colorbox{pink}{\\color{pink}soil}} {\\colorbox{pink}{\\color{pink}types}} {\\colorbox{pink}{\\color{pink}across}} {\\colorbox{pink}{\\color{pink}geographical}} {\\colorbox{pink}{\\color{pink}regions.}} {\\colorbox{pink}{\\color{pink}This}} {\\colorbox{pink}{\\color{pink}paper}} {\\colorbox{pink}{\\color{pink}proposes}} {\\colorbox{pink}{\\color{pink}a}} {\\colorbox{pink}{\\color{pink}crop}} {\\colorbox{pink}{\\color{pink}recommendation}} {\\colorbox{pink}{\\color{pink}system}} {\\colorbox{pink}{\\color{pink}that}} {\\colorbox{pink}{\\color{pink}uses}} {\\colorbox{pink}{\\color{pink}a}} {\\colorbox{pink}{\\color{pink}Convolutional}} {\\colorbox{pink}{\\color{pink}Neural}} {\\colorbox{pink}{\\color{pink}Network}} {\\colorbox{pink}{\\color{pink}(CNN)}} {\\colorbox{pink}{\\color{pink}and}} {\\colorbox{pink}{\\color{pink}a}} {\\colorbox{pink}{\\color{pink}Random}} {\\colorbox{pink}{\\color{pink}Forest}} {\\colorbox{pink}{\\color{pink}Model}} {\\colorbox{pink}{\\color{pink}to}} {\\colorbox{pink}{\\color{pink}predict}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}optimal}} {\\colorbox{pink}{\\color{pink}crop}} {\\colorbox{pink}{\\color{pink}to}} {\\colorbox{pink}{\\color{pink}be}} {\\colorbox{pink}{\\color{pink}grown}} {\\colorbox{pink}{\\color{pink}by}} {\\colorbox{pink}{\\color{pink}analyzing}} {\\colorbox{pink}{\\color{pink}various}} {\\colorbox{pink}{\\color{pink}parameters}} {\\colorbox{pink}{\\color{pink}including}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}region,}} {\\colorbox{pink}{\\color{pink}soil}} {\\colorbox{pink}{\\color{pink}type,}} {\\colorbox{pink}{\\color{pink}yield,}} {\\colorbox{pink}{\\color{pink}selling}} {\\colorbox{pink}{\\color{pink}price,}} {\\colorbox{pink}{\\color{pink}etc.}} {\\colorbox{pink}{\\color{pink}The}} {\\colorbox{pink}{\\color{pink}CNN}} {\\colorbox{pink}{\\color{pink}architecture}} {\\colorbox{pink}{\\color{pink}gave}} {\\colorbox{pink}{\\color{pink}an}} {\\colorbox{pink}{\\color{pink}accuracy}} {\\colorbox{pink}{\\color{pink}of}} {\\colorbox{pink}{\\color{pink}95.21}} \n",
            "{\\colorbox{pink}{\\color{pink}\\%}} \n",
            "{\\colorbox{pink}{\\color{pink},}} {\\colorbox{pink}{\\color{pink}and}} {\\colorbox{pink}{\\color{pink}the}} {\\colorbox{pink}{\\color{pink}Random}} {\\colorbox{pink}{\\color{pink}Forest}} {\\colorbox{pink}{\\color{pink}Algorithm}} {\\colorbox{pink}{\\color{pink}had}} {\\colorbox{pink}{\\color{pink}an}} {\\colorbox{pink}{\\color{pink}accuracy}} {\\colorbox{pink}{\\color{pink}of}} {\\colorbox{pink}{\\color{pink}75}} \n",
            "{\\colorbox{pink}{\\color{pink}\\%}} \n",
            "{\\colorbox{pink}{\\color{pink}.}} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section\n",
        "secs=list(toc.find_all('section'))\n",
        "for i in range(len(secs)):\n",
        "  secs[i].args[0].string=string_colorit(str(secs[i].args[0]),\"blue\")"
      ],
      "metadata": {
        "id": "U5wR3x35gAZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Images & Captions\n",
        "images=list(toc.find_all('figure'))\n",
        "for i in range(len(images)):\n",
        "  print(images[i].find(\"caption\").args[0].string)\n",
        "  images[i].find(\"caption\").args[0].string=string_colorit(str(images[i].find(\"caption\").args[0].string),\"orange\")\n",
        "  images[i].find(\"includegraphics\").args[1]=\"{magenta}\"\n",
        "# print(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "NQXakxAGEA2B",
        "outputId": "8a9fd3dd-16f8-42b1-9a85-8bd9abafe59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RecursionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-29cde5d52f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'includegraphics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'includegraphics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"magenta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, name, **attrs)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \"\"\"\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdescendant\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__descendants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescendant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__match__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                     \u001b[0mdescendant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__match__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m__descendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[1;32m    610\u001b[0m         return itertools.chain(self.contents,\n\u001b[0;32m--> 611\u001b[0;31m                                *[c.descendants for c in self.children])\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[1;32m    610\u001b[0m         return itertools.chain(self.contents,\n\u001b[0;32m--> 611\u001b[0;31m                                *[c.descendants for c in self.children])\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36mdescendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m<\u001b[0m\u001b[0mBLANKLINE\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__descendants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m__descendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[1;32m    610\u001b[0m         return itertools.chain(self.contents,\n\u001b[0;32m--> 611\u001b[0;31m                                *[c.descendants for c in self.children])\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[1;32m    610\u001b[0m         return itertools.chain(self.contents,\n\u001b[0;32m--> 611\u001b[0;31m                                *[c.descendants for c in self.children])\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36mdescendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m<\u001b[0m\u001b[0mBLANKLINE\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__descendants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m__descendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[1;32m    610\u001b[0m         return itertools.chain(self.contents,\n\u001b[0;32m--> 611\u001b[0;31m                                *[c.descendants for c in self.children])\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[1;32m    610\u001b[0m         return itertools.chain(self.contents,\n\u001b[0;32m--> 611\u001b[0;31m                                *[c.descendants for c in self.children])\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36mdescendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m<\u001b[0m\u001b[0mBLANKLINE\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__descendants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m__descendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[1;32m    610\u001b[0m         return itertools.chain(self.contents,\n\u001b[0;32m--> 611\u001b[0;31m                                *[c.descendants for c in self.children])\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[1;32m    610\u001b[0m         return itertools.chain(self.contents,\n\u001b[0;32m--> 611\u001b[0;31m                                *[c.descendants for c in self.children])\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36mdescendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m<\u001b[0m\u001b[0mBLANKLINE\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__descendants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m__descendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \"\"\"Implementation for descendants, hacky workaround for __getattr__\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[0;32m--> 610\u001b[0;31m         return itertools.chain(self.contents,\n\u001b[0m\u001b[1;32m    611\u001b[0m                                *[c.descendants for c in self.children])\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr, default)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m\"\"\"Convert all invalid attributes into basic find operation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, name, **attrs)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, name, **attrs)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \"\"\"\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdescendant\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__descendants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescendant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__match__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                     \u001b[0mdescendant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__match__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "... last 5 frames repeated, from the frame below ...\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/TexSoup/data.py\u001b[0m in \u001b[0;36m__descendants\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \"\"\"Implementation for descendants, hacky workaround for __getattr__\n\u001b[1;32m    609\u001b[0m         issues.\"\"\"\n\u001b[0;32m--> 610\u001b[0;31m         return itertools.chain(self.contents,\n\u001b[0m\u001b[1;32m    611\u001b[0m                                *[c.descendants for c in self.children])\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"latex/out.tex\", \"w\") as g:\n",
        "    g.write(str(toc))"
      ],
      "metadata": {
        "id": "AEDJwTXc1m9u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}